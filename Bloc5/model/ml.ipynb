{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45bb3eb",
   "metadata": {},
   "source": [
    "### Import des librairies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e566e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ac7c5",
   "metadata": {},
   "source": [
    "### Chargement des données\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3f4786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_key</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_power</th>\n",
       "      <th>fuel</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>car_type</th>\n",
       "      <th>private_parking_available</th>\n",
       "      <th>has_gps</th>\n",
       "      <th>has_air_conditioning</th>\n",
       "      <th>automatic_car</th>\n",
       "      <th>has_getaround_connect</th>\n",
       "      <th>has_speed_regulator</th>\n",
       "      <th>winter_tires</th>\n",
       "      <th>rental_price_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Citroën</td>\n",
       "      <td>140411</td>\n",
       "      <td>100</td>\n",
       "      <td>diesel</td>\n",
       "      <td>black</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Citroën</td>\n",
       "      <td>13929</td>\n",
       "      <td>317</td>\n",
       "      <td>petrol</td>\n",
       "      <td>grey</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Citroën</td>\n",
       "      <td>183297</td>\n",
       "      <td>120</td>\n",
       "      <td>diesel</td>\n",
       "      <td>white</td>\n",
       "      <td>convertible</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Citroën</td>\n",
       "      <td>128035</td>\n",
       "      <td>135</td>\n",
       "      <td>diesel</td>\n",
       "      <td>red</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Citroën</td>\n",
       "      <td>97097</td>\n",
       "      <td>160</td>\n",
       "      <td>diesel</td>\n",
       "      <td>silver</td>\n",
       "      <td>convertible</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 model_key  mileage  engine_power    fuel paint_color  \\\n",
       "0           0   Citroën   140411           100  diesel       black   \n",
       "1           1   Citroën    13929           317  petrol        grey   \n",
       "2           2   Citroën   183297           120  diesel       white   \n",
       "3           3   Citroën   128035           135  diesel         red   \n",
       "4           4   Citroën    97097           160  diesel      silver   \n",
       "\n",
       "      car_type  private_parking_available  has_gps  has_air_conditioning  \\\n",
       "0  convertible                       True     True                 False   \n",
       "1  convertible                       True     True                 False   \n",
       "2  convertible                      False    False                 False   \n",
       "3  convertible                       True     True                 False   \n",
       "4  convertible                       True     True                 False   \n",
       "\n",
       "   automatic_car  has_getaround_connect  has_speed_regulator  winter_tires  \\\n",
       "0          False                   True                 True          True   \n",
       "1          False                  False                 True          True   \n",
       "2          False                   True                False          True   \n",
       "3          False                   True                 True          True   \n",
       "4          False                  False                 True          True   \n",
       "\n",
       "   rental_price_per_day  \n",
       "0                   106  \n",
       "1                   264  \n",
       "2                   101  \n",
       "3                   158  \n",
       "4                   183  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/get_around_pricing_project.csv'\n",
    "df = pd.read_csv(path, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3723f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386246c",
   "metadata": {},
   "source": [
    "### Modéle Linéaire Regression Baseline\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36cec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Score R2 ===\n",
      "R2 Score (Train): 0.7140\n",
      "R2 Score (Test) : 0.6937\n",
      "\n",
      "=== RMSE ===\n",
      "RMSE : 322.59\n",
      "Prix moyen : 121.21 €\n",
      "Median AE : 8.19 €\n"
     ]
    }
   ],
   "source": [
    "# === 1. Séparation des données ===\n",
    "target = \"rental_price_per_day\"\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# === 2. Split du jeu de données ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 3. Pipeline de prétraitement ===\n",
    "numerical_columns = ['mileage', 'engine_power']\n",
    "categorical_columns = ['model_key', 'fuel', 'paint_color', 'car_type',\n",
    "                        'private_parking_available', 'has_gps', 'has_air_conditioning',\n",
    "                        'automatic_car', 'has_getaround_connect', 'has_speed_regulator', 'winter_tires']\n",
    "\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardization\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "feature_encoder = ColumnTransformer(transformers=[\n",
    "    (\"num\", numerical_pipeline, numerical_columns),\n",
    "    (\"cat\", categorical_pipeline, categorical_columns)\n",
    "])\n",
    "\n",
    "# Transformation des données\n",
    "X_train = feature_encoder.fit_transform(X_train)\n",
    "X_test = feature_encoder.transform(X_test)\n",
    "\n",
    "# === 4. Entraînement des modèles de régression === \n",
    "lin_reg = LinearRegression() \n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# === 5. Prédictions ===\n",
    "y_train_pred = lin_reg.predict(X_train)\n",
    "y_test_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# === 6. Évaluation des performances ===\n",
    "print(\"=== Score R2 ===\")\n",
    "print(f\"R2 Score (Train): {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"R2 Score (Test) : {r2_score(y_test, y_test_pred):.4f}\\n\")\n",
    "\n",
    "print(\"=== RMSE ===\")\n",
    "rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "\n",
    "# Prix moyen sur tout le dataset\n",
    "mean_price = df[\"rental_price_per_day\"].mean()\n",
    "print(f\"Prix moyen : {mean_price:.2f} €\")\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "medae = median_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Median AE : {medae:.2f} €\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0d82e",
   "metadata": {},
   "source": [
    "### Modéle RandomForestRegressor\n",
    "---\n",
    "#### RandomForestRegressor prédit un prix en construisant plusieurs arbres de décision indépendants et en moyennant leurs prédictions, ce qui rend la prédiction plus stable et robuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4daa18cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Score R2 ===\n",
      "R2 Score (Train): 0.9273\n",
      "R2 Score (Test) : 0.7386\n",
      "\n",
      "=== RMSE ===\n",
      "RMSE : 275.32\n",
      "Prix moyen : 121.21 €\n",
      "Median AE : 7.18 €\n",
      "\n",
      "Le modèle prédit très bien la tendance générale (R² test = 0,72).\n",
      "Le RMSE est élevé car il est sensible aux voitures très chères ou très bon marché,\n",
      "mais la Median Absolute Error de 7,1€ montre que pour la majorité des véhicules,\n",
      "nos prédictions sont très proches du prix réel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target = \"rental_price_per_day\"\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# Split du jeu de données ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline de prétraitement ===\n",
    "numerical_columns = ['mileage', 'engine_power']\n",
    "categorical_columns = ['model_key', 'fuel', 'paint_color', 'car_type',\n",
    "                        'private_parking_available', 'has_gps', 'has_air_conditioning',\n",
    "                        'automatic_car', 'has_getaround_connect', 'has_speed_regulator', 'winter_tires']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardization\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_columns),\n",
    "        (\"cat\", categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Création du pipeline complet\n",
    "# n_estimators=100 → assez d’arbres pour stabiliser le modèle.\n",
    "# max_depth=9 → limite la complexité des arbres pour mieux généraliser sur le test.\n",
    "# random_state=42 → assure que les résultats sont toujours identiques.\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=12, random_state=42) #100 arbres dans la foret - chaque arbre à max 9 niveaux de decisions - \n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", model) \n",
    "])\n",
    "\n",
    "# Entraînement\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction \n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Évaluation des performances\n",
    "\n",
    "print(\"=== Score R2 ===\")\n",
    "print(f\"R2 Score (Train): {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"R2 Score (Test) : {r2_score(y_test, y_test_pred):.4f}\\n\")\n",
    "\n",
    "print(\"=== RMSE ===\")\n",
    "rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "\n",
    "# Prix moyen sur tout le dataset\n",
    "mean_price = df[\"rental_price_per_day\"].mean()\n",
    "print(f\"Prix moyen : {mean_price:.2f} €\")\n",
    "\n",
    "medae = median_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Median AE : {medae:.2f} €\")\n",
    "\n",
    "print(\"\\nLe modèle prédit très bien la tendance générale (R² test = 0,72).\\nLe RMSE est élevé car il est sensible aux voitures très chères ou très bon marché,\\nmais la Median Absolute Error de 7,1€ montre que pour la majorité des véhicules,\\nnos prédictions sont très proches du prix réel.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1c12b",
   "metadata": {},
   "source": [
    "### Modéle XGBoost\n",
    "---\n",
    "#### XGBoost (eXtreme Gradient Boosting) est un algorithme de Gradient Boosting basé sur des arbres de décision, optimisé pour la vitesse et la performance, où chaque nouvel arbre corrige les erreurs des arbres précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ba531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Score R2 ===\n",
      "R2 Score (Train): 0.9886\n",
      "R2 Score (Test) : 0.7406\n",
      "\n",
      "=== RMSE ===\n",
      "RMSE : 273.23\n",
      "Prix moyen : 121.21 €\n",
      "Median AE : 6.44 €\n",
      "\n",
      "Le modèle XGBoost améliore le R2 test avec 0.74, cependant il overfite avec un train à 0.98 (écart à 0.16)\n"
     ]
    }
   ],
   "source": [
    "# Target et features\n",
    "target = \"rental_price_per_day\"\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Colonnes numériques et catégorielles\n",
    "numerical_columns = ['mileage', 'engine_power']\n",
    "categorical_columns = ['model_key', 'fuel', 'paint_color', 'car_type',\n",
    "                       'private_parking_available', 'has_gps', 'has_air_conditioning',\n",
    "                       'automatic_car', 'has_getaround_connect', 'has_speed_regulator', 'winter_tires']\n",
    "\n",
    "# Prétraitement numérique\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Prétraitement catégoriel\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numerical_columns),\n",
    "    (\"cat\", categorical_transformer, categorical_columns)\n",
    "])\n",
    "\n",
    "# Modèle XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,      # nombre d'arbres\n",
    "    max_depth=9,           # profondeur maximale\n",
    "    learning_rate=0.1,     # taux d'apprentissage : Contrôle combien chaque arbre corrige l’erreur du précédent. Plus petit = apprentissage plus lent et stable.\n",
    "    subsample=0.8,         # échantillonnage pour régularisation : fraction des échantillons utilisés pour chaque arbre.Introduit un peu d’aléatoire pour réduire l’overfitting.\n",
    ")\n",
    "\n",
    "# Pipeline complet\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", xgb_model)\n",
    "])\n",
    "\n",
    "# Entraînement\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"=== Score R2 ===\")\n",
    "print(f\"R2 Score (Train): {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"R2 Score (Test) : {r2_score(y_test, y_test_pred):.4f}\\n\")\n",
    "\n",
    "print(\"=== RMSE ===\")\n",
    "rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "\n",
    "mean_price = df[\"rental_price_per_day\"].mean()\n",
    "print(f\"Prix moyen : {mean_price:.2f} €\")\n",
    "\n",
    "medae = median_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Median AE : {medae:.2f} €\")\n",
    "\n",
    "print(\"\\nLe modèle XGBoost améliore le R2 test avec 0.74, cependant il overfite avec un train à 0.98 (écart à 0.16)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ec65a",
   "metadata": {},
   "source": [
    "### Modéle XGBoost + GridSearch\n",
    "---\n",
    "#### GridSearchCV est un outil qui permet de chercher les meilleures combinaisons de paramètres pour un modèle, afin d’optimiser sa performance. Après avoir entraîné le GridSearch, je récupère best_estimator_, qui contient le pipeline complet optimisé, et je le sauvegarde immédiatement avec joblib.dump. Cela me permet de le recharger plus tard pour prédire sur de nouvelles données sans refaire le prétraitement ni réentraîner le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2ae9c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8b0cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Meilleurs paramètres :  {'regressor__learning_rate': 0.05, 'regressor__max_depth': 4, 'regressor__n_estimators': 200, 'regressor__subsample': 0.8}\n",
      "Meilleur R2 CV :  0.7517865300178528\n",
      "✅ Modèle sauvegardé sous : modele_xgb_getaround.pkl\n",
      "=== Score R2 ===\n",
      "R2 Score (Train): 0.8234\n",
      "R2 Score (Test) : 0.7470\n",
      "\n",
      "=== RMSE ===\n",
      "RMSE : 266.42\n",
      "Prix moyen : 121.21 €\n",
      "Median AE : 6.84 €\n",
      "\n",
      "Après optimisation via GridSearch, le modèle présente une meilleure performance avec un R² test de 0.75,\n",
      "tout en réduisant l’overfitting avec le R² train de 0.82 (écart de 0.07).\n",
      "Le modèle est ainsi plus robuste et stable.\n"
     ]
    }
   ],
   "source": [
    "# Target et features\n",
    "target = \"rental_price_per_day\"\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Colonnes numériques et catégorielles\n",
    "numerical_columns = ['mileage', 'engine_power']\n",
    "categorical_columns = ['model_key', 'fuel', 'paint_color', 'car_type',\n",
    "                       'private_parking_available', 'has_gps', 'has_air_conditioning',\n",
    "                       'automatic_car', 'has_getaround_connect', 'has_speed_regulator', 'winter_tires']\n",
    "\n",
    "# Prétraitement numérique\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Prétraitement catégoriel\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numerical_columns),\n",
    "    (\"cat\", categorical_transformer, categorical_columns)\n",
    "])\n",
    "\n",
    "# Modèle XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "# Pipeline complet\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", xgb_model)\n",
    "])\n",
    "\n",
    "# Paramètres pour GridSearch (réduits pour éviter surcharge)\n",
    "param_grid = {\n",
    "    \"regressor__max_depth\": [3, 4],\n",
    "    \"regressor__learning_rate\": [0.05, 0.1],\n",
    "    \"regressor__n_estimators\": [100, 200],\n",
    "    \"regressor__subsample\": [0.8],\n",
    "}\n",
    "\n",
    "# GridSearch avec 3-fold CV pour limiter le temps\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Entraînement GridSearch\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres et score CV\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleur R2 CV : \", grid_search.best_score_)\n",
    "\n",
    "# Sauvegarde du pipeline complet\n",
    "# On récupère le pipeline optimisé (prétraitement + XGBoost avec les meilleurs hyperparamètres)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Sauvegarde au format .pkl\n",
    "joblib.dump(best_model, \"modele_xgb_getaround.pkl\")\n",
    "print(\"✅ Modèle sauvegardé sous : modele_xgb_getaround.pkl\")\n",
    "\n",
    "\n",
    "# Prédictions avec le meilleur modèle\n",
    "y_train_pred = grid_search.best_estimator_.predict(X_train)\n",
    "y_test_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"=== Score R2 ===\")\n",
    "print(f\"R2 Score (Train): {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"R2 Score (Test) : {r2_score(y_test, y_test_pred):.4f}\\n\")\n",
    "\n",
    "print(\"=== RMSE ===\")\n",
    "rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "\n",
    "mean_price = df[\"rental_price_per_day\"].mean()\n",
    "print(f\"Prix moyen : {mean_price:.2f} €\")\n",
    "\n",
    "medae = median_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Median AE : {medae:.2f} €\")\n",
    "\n",
    "print(\"\\nAprès optimisation via GridSearch, le modèle présente une meilleure performance avec un R² test de 0.75,\\ntout en réduisant l’overfitting avec le R² train de 0.82 (écart de 0.07).\\nLe modèle est ainsi plus robuste et stable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e772b",
   "metadata": {},
   "source": [
    "### Enregistrement du modèle et des métriques dans MLflow\n",
    "---\n",
    "### Après la recherche d’hyperparamètres avec GridSearch, j’ai récupéré grid_search.best_estimator_, qui contient le pipeline complet (prétraitement + XGBoost optimisé). Je l’ai sauvegardé avec joblib.dump. Ensuite, dans mon application, je recharge ce fichier avec joblib.load, ce qui me permet de prédire directement sur de nouvelles données sans refaire tout le preprocessing. »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00be5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Démarre une session MLflow\n",
    "# with mlflow.start_run():\n",
    "#     # Enregistre le pipeline complet\n",
    "#     mlflow.sklearn.log_model(pipeline, \"random_forest_model\")\n",
    "    \n",
    "#     # Log des métriques calculées\n",
    "#     mlflow.log_metric(\"R2_train\", r2_score(y_train, y_train_pred))\n",
    "#     mlflow.log_metric(\"R2_test\", r2_score(y_test, y_test_pred))\n",
    "#     mlflow.log_metric(\"RMSE\", mean_squared_error(y_test, y_test_pred))  # RMSE = sqrt(MSE)\n",
    "#     mlflow.log_metric(\"MedianAE\", median_absolute_error(y_test, y_test_pred))\n",
    "    \n",
    "#     print(\"Modèle et métriques enregistrés dans MLflow\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
